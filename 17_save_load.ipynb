{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984d3270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c38c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 3 DIFFERENT METHODS TO REMEMBER:\n",
    " - torch.save(arg, PATH) # can be model, tensor, or dictionary\n",
    " - torch.load(PATH)\n",
    " - torch.load_state_dict(arg)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1cdd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 2 DIFFERENT WAYS OF SAVING\n",
    "# 1) lazy way: save whole model\n",
    "torch.save(model, PATH)\n",
    "\n",
    "# model class must be defined somewhere\n",
    "model = torch.load(PATH)\n",
    "model.eval()\n",
    "\n",
    "# 2) recommended way: save only the state_dict\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# model must be created again with parameters\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4207769",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339975c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(n_input_features=6)\n",
    "# train your model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d862d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################save all ######################################\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ec2168",
   "metadata": {},
   "source": [
    "save and load entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843bd3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = \"model.pth\"\n",
    "torch.save(model, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3de360",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load(FILE)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5301bf0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for param in loaded_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50655322",
   "metadata": {},
   "source": [
    "###########save only state dict #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8bcc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save only state dict\n",
    "FILE = \"model.pth\"\n",
    "torch.save(model.state_dict(), FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict())\n",
    "loaded_model = Model(n_input_features=6)\n",
    "loaded_model.load_state_dict(torch.load(FILE)) # it takes the loaded dictionary, not the path file itself\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df93aa2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(loaded_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a5c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########load checkpoint#####################\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3f5446",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "\"epoch\": 90,\n",
    "\"model_state\": model.state_dict(),\n",
    "\"optim_state\": optimizer.state_dict()\n",
    "}\n",
    "print(optimizer.state_dict())\n",
    "FILE = \"checkpoint.pth\"\n",
    "torch.save(checkpoint, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(n_input_features=6)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bed451",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(FILE)\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "optimizer.load_state_dict(checkpoint['optim_state'])\n",
    "epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d51388",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# - or -\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea78d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3439153e",
   "metadata": {},
   "source": [
    "Remember that you must call model.eval() to set dropout and batch normalization layers \n",
    "to evaluation mode before running inference. Failing to do this will yield \n",
    "inconsistent inference results. If you wish to resuming training, \n",
    "call model.train() to ensure these layers are in training mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7158d5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\"\"\" SAVING ON GPU/CPU \n",
    "\n",
    "# 1) Save on GPU, Load on CPU\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))\n",
    "\n",
    "# 2) Save on GPU, Load on GPU\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n",
    "\n",
    "# Note: Be sure to use the .to(torch.device('cuda')) function \n",
    "# on all model inputs, too!\n",
    "\n",
    "# 3) Save on CPU, Load on GPU\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\n",
    "model.to(device)\n",
    "\n",
    "# This loads the model to a given GPU device. \n",
    "# Next, be sure to call model.to(torch.device('cuda')) to convert the modelâ€™s parameter tensors to CUDA tensors\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
